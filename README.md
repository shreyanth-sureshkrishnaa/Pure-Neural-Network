# Pure-Neural-Network
A neural network built from scratch. 

## [NOTEBOOK LINK](https://colab.research.google.com/drive/1F4LWc3Xp52PwpmDbYKJBwBzbOweoV-cK?usp=sharing)
## Neural Networks Introduction

This repository contains a beginner-friendly exploration of neural networks, featuring two implementations:

A neural network built entirely from scratch using only Python and NumPy.

A neural network implemented using scikit-learn for comparison and experimentation.

The goal of this project is to illustrate how neural networks operate under the hood while also demonstrating how high-level libraries abstract away much of the manual work. This notebook focuses on the implementation details and intuition rather than the deep mathematical foundations.

## What This Notebook Covers

<ul>
  <li>Forward propagation</li>
  <li>Backpropagation</li>
  <li>Loss calculation</li>
  <li>Parameter updates</li>
  <li>Activation functions</li>
  <li>Network evaluation</li>
</ul>


## Comparison with scikit-learn's MLPClassifier

The from-scratch implementation is adapted from Aadil Malick’s excellent Medium article “Learn to Build a Neural Network From Scratch — Yes, Really.” Some explanations also draw on Kaggle’s free course “Introduction to Deep Learning.”

## What This Notebook Does Not Cover

This notebook is not a full mathematical introduction to neural networks. It assumes familiarity with:

<ul>
<li>Basic linear algebra</li>
<li>Derivatives and gradients</li>
<li>Fundamental machine learning terminology</li>
<li>Activation functions</li>
</ul>

